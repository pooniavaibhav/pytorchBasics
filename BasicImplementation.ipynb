{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BasicImplementation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMdo7/Jimj1ygItw2YkRNlO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pooniavaibhav/pytorchBasics/blob/main/BasicImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFnzNIk4SZ3E"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMtnNODOTB_k"
      },
      "source": [
        "# load the dataset using pandas-\n",
        "data = pd.read_csv(\"/diabetes.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaE1TIy-UBd9"
      },
      "source": [
        "# taking x and y and converting into numpy array using .values\n",
        "x = data.iloc[:,:-1].values\n",
        "y_string = data.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE1j1gKVUpkH"
      },
      "source": [
        "# convert the string into 0 and 1\n",
        "y_int = [1 if i==\"positive\" else 0 for i in y_string]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpXQ5PxjXGp5"
      },
      "source": [
        "# convert it to numpy array-\n",
        "y = np.array(y_int, dtype='float64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85Bm40a-Xjf0"
      },
      "source": [
        "#Normalisation-\n",
        "sc = StandardScaler()\n",
        "x = sc.fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "437uEuzGaJeP"
      },
      "source": [
        "# convert the arrays to pytorch tensors\n",
        "x = torch.tensor(x)\n",
        "y = torch.tensor(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRSiW2BPcg46",
        "outputId": "44acc67f-3cc7-4313-bab0-8d12e517e792"
      },
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([768, 7])\n",
            "torch.Size([768, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHJuPcUfch_y",
        "outputId": "f19e2010-4884-4463-cfaf-cfd358e6dfe8"
      },
      "source": [
        "#since we will be using binary cross entropy we need to convert y into 2D-\n",
        "y = torch.tensor(y).unsqueeze(1)\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NL0hGzwdUtd"
      },
      "source": [
        "# build custom pytorch datatset-\n",
        "class Dataset(Dataset):\n",
        "\n",
        "  def __init__(self,x,y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7M0MTO9elSn"
      },
      "source": [
        "dataset = Dataset(x,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4clN674EertY"
      },
      "source": [
        "#load the  data to your dataloader for batch processing and shuffling-\n",
        "train_loader = DataLoader(dataset = dataset, batch_size=32, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvubbez3gJ0w",
        "outputId": "37f9027c-6a4b-4284-a817-69dd23aa32e2"
      },
      "source": [
        "#lets have a look at the data loader-\n",
        "print(\"There is {} batches in the dataset\".format(len(train_loader)))\n",
        "for (x,y) in train_loader:\n",
        "  print(\"For one iteration (batch), there is:\")\n",
        "  print(\"Data:     {}\".format(x.shape))\n",
        "  print(\"Labels:    {}\".format(y.shape))\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There is 24 batches in the dataset\n",
            "For one iteration (batch), there is:\n",
            "Data:     torch.Size([32, 7])\n",
            "Labels:    torch.Size([32, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wbh3o6RjN9g"
      },
      "source": [
        "#building a neural network-\n",
        "class Model(nn.Module):\n",
        "  def __init__(self,input_features,output_features):\n",
        "    super(Model,self).__init__()\n",
        "    self.fc1 = nn.Linear(input_features, 5)\n",
        "    self.fc2 = nn.Linear(5,4)\n",
        "    self.fc3 = nn.Linear(4,3)\n",
        "    self.fc4 = nn.Linear(3,output_features)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.tanh = nn.Tanh()\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.tanh(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.tanh(out)\n",
        "    out = self.fc3(out)\n",
        "    out = self.tanh(out)\n",
        "    out = self.fc4(out)\n",
        "    out = self.sigmoid(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTYxFXXEsaba",
        "outputId": "c173fb49-d4bd-42c1-a28a-ddf56a23f932"
      },
      "source": [
        "#create the network (an object of the Net class)\n",
        "net = Model(7,1)\n",
        "# In cross entropy the input and the output should have the same shape.\n",
        "# size_average = True --> the losses are averaged over observations for each minibatch\n",
        "criterion  = torch.nn.BCELoss(size_average=True)\n",
        "#we will use SGD with momentum with a learning rate of 0.1\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr = 0.1, momentum = 0.9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRqF8EzfvMYZ",
        "outputId": "7a1cea42-9a59-4ab0-ea7b-58d2c81e8735"
      },
      "source": [
        "# training the network-\n",
        "epochs = 200\n",
        "for epoch in range(200):\n",
        "  for inputs,labels in train_loader:\n",
        "    inputs = inputs.float()\n",
        "    labels = labels.float()\n",
        "    # forward prop\n",
        "    outputs = net(inputs)\n",
        "    # loss clculation\n",
        "    loss = criterion(outputs, labels)\n",
        "    #clear the gradient buffer\n",
        "    optimizer.zero_grad()\n",
        "    # Backprop\n",
        "    loss.backward()\n",
        "    #update weight-\n",
        "    optimizer.step()\n",
        "  #Accuracy calculation\n",
        "  output = (outputs>0.5).float()\n",
        "  accuracy = (outputs == labels).float().mean()\n",
        "  #print stats\n",
        "  print(\"Epochs {}/{}, Loss: {:,.3f}, Accuracy: {:,.3f}\".format(epoch+1, epochs, loss, accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs 1/200, Loss: 0.443, Accuracy: 0.000\n",
            "Epochs 2/200, Loss: 0.638, Accuracy: 0.000\n",
            "Epochs 3/200, Loss: 0.427, Accuracy: 0.000\n",
            "Epochs 4/200, Loss: 0.471, Accuracy: 0.000\n",
            "Epochs 5/200, Loss: 0.450, Accuracy: 0.000\n",
            "Epochs 6/200, Loss: 0.282, Accuracy: 0.000\n",
            "Epochs 7/200, Loss: 0.419, Accuracy: 0.000\n",
            "Epochs 8/200, Loss: 0.635, Accuracy: 0.000\n",
            "Epochs 9/200, Loss: 0.370, Accuracy: 0.000\n",
            "Epochs 10/200, Loss: 0.522, Accuracy: 0.000\n",
            "Epochs 11/200, Loss: 0.373, Accuracy: 0.000\n",
            "Epochs 12/200, Loss: 0.548, Accuracy: 0.000\n",
            "Epochs 13/200, Loss: 0.378, Accuracy: 0.000\n",
            "Epochs 14/200, Loss: 0.388, Accuracy: 0.000\n",
            "Epochs 15/200, Loss: 0.482, Accuracy: 0.000\n",
            "Epochs 16/200, Loss: 0.455, Accuracy: 0.000\n",
            "Epochs 17/200, Loss: 0.565, Accuracy: 0.000\n",
            "Epochs 18/200, Loss: 0.509, Accuracy: 0.000\n",
            "Epochs 19/200, Loss: 0.546, Accuracy: 0.000\n",
            "Epochs 20/200, Loss: 0.654, Accuracy: 0.000\n",
            "Epochs 21/200, Loss: 0.538, Accuracy: 0.000\n",
            "Epochs 22/200, Loss: 0.542, Accuracy: 0.000\n",
            "Epochs 23/200, Loss: 0.356, Accuracy: 0.000\n",
            "Epochs 24/200, Loss: 0.567, Accuracy: 0.000\n",
            "Epochs 25/200, Loss: 0.497, Accuracy: 0.000\n",
            "Epochs 26/200, Loss: 0.587, Accuracy: 0.000\n",
            "Epochs 27/200, Loss: 0.392, Accuracy: 0.000\n",
            "Epochs 28/200, Loss: 0.443, Accuracy: 0.000\n",
            "Epochs 29/200, Loss: 0.389, Accuracy: 0.000\n",
            "Epochs 30/200, Loss: 0.260, Accuracy: 0.000\n",
            "Epochs 31/200, Loss: 0.362, Accuracy: 0.000\n",
            "Epochs 32/200, Loss: 0.389, Accuracy: 0.000\n",
            "Epochs 33/200, Loss: 0.545, Accuracy: 0.000\n",
            "Epochs 34/200, Loss: 0.396, Accuracy: 0.000\n",
            "Epochs 35/200, Loss: 0.738, Accuracy: 0.000\n",
            "Epochs 36/200, Loss: 0.356, Accuracy: 0.000\n",
            "Epochs 37/200, Loss: 0.385, Accuracy: 0.000\n",
            "Epochs 38/200, Loss: 0.467, Accuracy: 0.000\n",
            "Epochs 39/200, Loss: 0.355, Accuracy: 0.000\n",
            "Epochs 40/200, Loss: 0.461, Accuracy: 0.000\n",
            "Epochs 41/200, Loss: 0.338, Accuracy: 0.000\n",
            "Epochs 42/200, Loss: 0.345, Accuracy: 0.000\n",
            "Epochs 43/200, Loss: 0.460, Accuracy: 0.000\n",
            "Epochs 44/200, Loss: 0.659, Accuracy: 0.000\n",
            "Epochs 45/200, Loss: 0.463, Accuracy: 0.000\n",
            "Epochs 46/200, Loss: 0.373, Accuracy: 0.000\n",
            "Epochs 47/200, Loss: 0.707, Accuracy: 0.000\n",
            "Epochs 48/200, Loss: 0.503, Accuracy: 0.000\n",
            "Epochs 49/200, Loss: 0.406, Accuracy: 0.000\n",
            "Epochs 50/200, Loss: 0.357, Accuracy: 0.000\n",
            "Epochs 51/200, Loss: 0.671, Accuracy: 0.000\n",
            "Epochs 52/200, Loss: 0.227, Accuracy: 0.000\n",
            "Epochs 53/200, Loss: 0.382, Accuracy: 0.000\n",
            "Epochs 54/200, Loss: 0.414, Accuracy: 0.000\n",
            "Epochs 55/200, Loss: 0.338, Accuracy: 0.000\n",
            "Epochs 56/200, Loss: 0.276, Accuracy: 0.000\n",
            "Epochs 57/200, Loss: 0.240, Accuracy: 0.000\n",
            "Epochs 58/200, Loss: 0.492, Accuracy: 0.000\n",
            "Epochs 59/200, Loss: 0.831, Accuracy: 0.000\n",
            "Epochs 60/200, Loss: 0.490, Accuracy: 0.000\n",
            "Epochs 61/200, Loss: 0.353, Accuracy: 0.000\n",
            "Epochs 62/200, Loss: 0.470, Accuracy: 0.000\n",
            "Epochs 63/200, Loss: 0.497, Accuracy: 0.000\n",
            "Epochs 64/200, Loss: 0.361, Accuracy: 0.000\n",
            "Epochs 65/200, Loss: 0.419, Accuracy: 0.000\n",
            "Epochs 66/200, Loss: 0.348, Accuracy: 0.000\n",
            "Epochs 67/200, Loss: 0.457, Accuracy: 0.000\n",
            "Epochs 68/200, Loss: 0.479, Accuracy: 0.000\n",
            "Epochs 69/200, Loss: 0.279, Accuracy: 0.000\n",
            "Epochs 70/200, Loss: 0.415, Accuracy: 0.000\n",
            "Epochs 71/200, Loss: 0.509, Accuracy: 0.000\n",
            "Epochs 72/200, Loss: 0.278, Accuracy: 0.000\n",
            "Epochs 73/200, Loss: 0.314, Accuracy: 0.000\n",
            "Epochs 74/200, Loss: 0.481, Accuracy: 0.000\n",
            "Epochs 75/200, Loss: 0.451, Accuracy: 0.000\n",
            "Epochs 76/200, Loss: 0.397, Accuracy: 0.000\n",
            "Epochs 77/200, Loss: 0.450, Accuracy: 0.000\n",
            "Epochs 78/200, Loss: 0.563, Accuracy: 0.000\n",
            "Epochs 79/200, Loss: 0.398, Accuracy: 0.000\n",
            "Epochs 80/200, Loss: 0.462, Accuracy: 0.000\n",
            "Epochs 81/200, Loss: 0.511, Accuracy: 0.000\n",
            "Epochs 82/200, Loss: 0.377, Accuracy: 0.000\n",
            "Epochs 83/200, Loss: 0.291, Accuracy: 0.000\n",
            "Epochs 84/200, Loss: 0.428, Accuracy: 0.000\n",
            "Epochs 85/200, Loss: 0.273, Accuracy: 0.000\n",
            "Epochs 86/200, Loss: 0.477, Accuracy: 0.000\n",
            "Epochs 87/200, Loss: 0.397, Accuracy: 0.000\n",
            "Epochs 88/200, Loss: 0.672, Accuracy: 0.000\n",
            "Epochs 89/200, Loss: 0.384, Accuracy: 0.000\n",
            "Epochs 90/200, Loss: 0.393, Accuracy: 0.000\n",
            "Epochs 91/200, Loss: 0.303, Accuracy: 0.000\n",
            "Epochs 92/200, Loss: 0.631, Accuracy: 0.000\n",
            "Epochs 93/200, Loss: 0.376, Accuracy: 0.000\n",
            "Epochs 94/200, Loss: 0.531, Accuracy: 0.000\n",
            "Epochs 95/200, Loss: 0.461, Accuracy: 0.000\n",
            "Epochs 96/200, Loss: 0.499, Accuracy: 0.000\n",
            "Epochs 97/200, Loss: 0.497, Accuracy: 0.000\n",
            "Epochs 98/200, Loss: 0.439, Accuracy: 0.000\n",
            "Epochs 99/200, Loss: 0.430, Accuracy: 0.000\n",
            "Epochs 100/200, Loss: 0.484, Accuracy: 0.000\n",
            "Epochs 101/200, Loss: 0.443, Accuracy: 0.000\n",
            "Epochs 102/200, Loss: 0.403, Accuracy: 0.000\n",
            "Epochs 103/200, Loss: 0.364, Accuracy: 0.000\n",
            "Epochs 104/200, Loss: 0.626, Accuracy: 0.000\n",
            "Epochs 105/200, Loss: 0.436, Accuracy: 0.000\n",
            "Epochs 106/200, Loss: 0.461, Accuracy: 0.000\n",
            "Epochs 107/200, Loss: 0.271, Accuracy: 0.000\n",
            "Epochs 108/200, Loss: 0.211, Accuracy: 0.000\n",
            "Epochs 109/200, Loss: 0.140, Accuracy: 0.000\n",
            "Epochs 110/200, Loss: 0.332, Accuracy: 0.000\n",
            "Epochs 111/200, Loss: 0.437, Accuracy: 0.000\n",
            "Epochs 112/200, Loss: 0.426, Accuracy: 0.000\n",
            "Epochs 113/200, Loss: 0.306, Accuracy: 0.000\n",
            "Epochs 114/200, Loss: 0.431, Accuracy: 0.000\n",
            "Epochs 115/200, Loss: 0.443, Accuracy: 0.000\n",
            "Epochs 116/200, Loss: 0.306, Accuracy: 0.000\n",
            "Epochs 117/200, Loss: 0.398, Accuracy: 0.000\n",
            "Epochs 118/200, Loss: 0.345, Accuracy: 0.000\n",
            "Epochs 119/200, Loss: 0.367, Accuracy: 0.000\n",
            "Epochs 120/200, Loss: 0.292, Accuracy: 0.000\n",
            "Epochs 121/200, Loss: 0.419, Accuracy: 0.000\n",
            "Epochs 122/200, Loss: 0.405, Accuracy: 0.000\n",
            "Epochs 123/200, Loss: 0.461, Accuracy: 0.000\n",
            "Epochs 124/200, Loss: 0.330, Accuracy: 0.000\n",
            "Epochs 125/200, Loss: 0.390, Accuracy: 0.000\n",
            "Epochs 126/200, Loss: 0.286, Accuracy: 0.000\n",
            "Epochs 127/200, Loss: 0.234, Accuracy: 0.000\n",
            "Epochs 128/200, Loss: 0.314, Accuracy: 0.000\n",
            "Epochs 129/200, Loss: 0.355, Accuracy: 0.000\n",
            "Epochs 130/200, Loss: 0.488, Accuracy: 0.000\n",
            "Epochs 131/200, Loss: 0.369, Accuracy: 0.000\n",
            "Epochs 132/200, Loss: 0.387, Accuracy: 0.000\n",
            "Epochs 133/200, Loss: 0.502, Accuracy: 0.000\n",
            "Epochs 134/200, Loss: 0.367, Accuracy: 0.000\n",
            "Epochs 135/200, Loss: 0.425, Accuracy: 0.000\n",
            "Epochs 136/200, Loss: 0.181, Accuracy: 0.000\n",
            "Epochs 137/200, Loss: 0.686, Accuracy: 0.000\n",
            "Epochs 138/200, Loss: 0.294, Accuracy: 0.000\n",
            "Epochs 139/200, Loss: 0.289, Accuracy: 0.000\n",
            "Epochs 140/200, Loss: 0.545, Accuracy: 0.000\n",
            "Epochs 141/200, Loss: 0.274, Accuracy: 0.000\n",
            "Epochs 142/200, Loss: 0.476, Accuracy: 0.000\n",
            "Epochs 143/200, Loss: 0.319, Accuracy: 0.000\n",
            "Epochs 144/200, Loss: 0.419, Accuracy: 0.000\n",
            "Epochs 145/200, Loss: 0.593, Accuracy: 0.000\n",
            "Epochs 146/200, Loss: 0.424, Accuracy: 0.000\n",
            "Epochs 147/200, Loss: 0.309, Accuracy: 0.000\n",
            "Epochs 148/200, Loss: 0.354, Accuracy: 0.000\n",
            "Epochs 149/200, Loss: 0.358, Accuracy: 0.000\n",
            "Epochs 150/200, Loss: 0.394, Accuracy: 0.000\n",
            "Epochs 151/200, Loss: 0.331, Accuracy: 0.000\n",
            "Epochs 152/200, Loss: 0.334, Accuracy: 0.000\n",
            "Epochs 153/200, Loss: 0.433, Accuracy: 0.000\n",
            "Epochs 154/200, Loss: 0.457, Accuracy: 0.000\n",
            "Epochs 155/200, Loss: 0.382, Accuracy: 0.000\n",
            "Epochs 156/200, Loss: 0.396, Accuracy: 0.000\n",
            "Epochs 157/200, Loss: 0.389, Accuracy: 0.000\n",
            "Epochs 158/200, Loss: 0.469, Accuracy: 0.000\n",
            "Epochs 159/200, Loss: 0.289, Accuracy: 0.000\n",
            "Epochs 160/200, Loss: 0.308, Accuracy: 0.000\n",
            "Epochs 161/200, Loss: 0.476, Accuracy: 0.000\n",
            "Epochs 162/200, Loss: 0.369, Accuracy: 0.000\n",
            "Epochs 163/200, Loss: 0.382, Accuracy: 0.000\n",
            "Epochs 164/200, Loss: 0.223, Accuracy: 0.000\n",
            "Epochs 165/200, Loss: 0.530, Accuracy: 0.000\n",
            "Epochs 166/200, Loss: 0.385, Accuracy: 0.000\n",
            "Epochs 167/200, Loss: 0.558, Accuracy: 0.000\n",
            "Epochs 168/200, Loss: 0.442, Accuracy: 0.000\n",
            "Epochs 169/200, Loss: 0.501, Accuracy: 0.000\n",
            "Epochs 170/200, Loss: 0.304, Accuracy: 0.000\n",
            "Epochs 171/200, Loss: 0.425, Accuracy: 0.000\n",
            "Epochs 172/200, Loss: 0.555, Accuracy: 0.000\n",
            "Epochs 173/200, Loss: 0.378, Accuracy: 0.000\n",
            "Epochs 174/200, Loss: 0.239, Accuracy: 0.000\n",
            "Epochs 175/200, Loss: 0.307, Accuracy: 0.000\n",
            "Epochs 176/200, Loss: 0.329, Accuracy: 0.000\n",
            "Epochs 177/200, Loss: 0.490, Accuracy: 0.000\n",
            "Epochs 178/200, Loss: 0.417, Accuracy: 0.000\n",
            "Epochs 179/200, Loss: 0.497, Accuracy: 0.000\n",
            "Epochs 180/200, Loss: 0.274, Accuracy: 0.000\n",
            "Epochs 181/200, Loss: 0.192, Accuracy: 0.000\n",
            "Epochs 182/200, Loss: 0.344, Accuracy: 0.000\n",
            "Epochs 183/200, Loss: 0.369, Accuracy: 0.000\n",
            "Epochs 184/200, Loss: 0.325, Accuracy: 0.000\n",
            "Epochs 185/200, Loss: 0.282, Accuracy: 0.000\n",
            "Epochs 186/200, Loss: 0.309, Accuracy: 0.000\n",
            "Epochs 187/200, Loss: 0.506, Accuracy: 0.000\n",
            "Epochs 188/200, Loss: 0.461, Accuracy: 0.000\n",
            "Epochs 189/200, Loss: 0.418, Accuracy: 0.000\n",
            "Epochs 190/200, Loss: 0.356, Accuracy: 0.000\n",
            "Epochs 191/200, Loss: 0.281, Accuracy: 0.000\n",
            "Epochs 192/200, Loss: 0.463, Accuracy: 0.000\n",
            "Epochs 193/200, Loss: 0.320, Accuracy: 0.000\n",
            "Epochs 194/200, Loss: 0.492, Accuracy: 0.000\n",
            "Epochs 195/200, Loss: 0.455, Accuracy: 0.000\n",
            "Epochs 196/200, Loss: 0.519, Accuracy: 0.000\n",
            "Epochs 197/200, Loss: 0.318, Accuracy: 0.000\n",
            "Epochs 198/200, Loss: 0.438, Accuracy: 0.000\n",
            "Epochs 199/200, Loss: 0.270, Accuracy: 0.000\n",
            "Epochs 200/200, Loss: 0.441, Accuracy: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRVQzJ1A3Sw_"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}